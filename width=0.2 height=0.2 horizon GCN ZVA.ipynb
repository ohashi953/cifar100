{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, Activation, add, Add, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "\n",
    "x_train = x_train.astype('float32')/255.0\n",
    "y_train = np.eye(100)[y_train.astype('int32').flatten()]\n",
    "x_test = x_test.astype('float32')/255.0\n",
    "y_test = np.eye(100)[y_test.astype('int32').flatten()]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train, y_train, test_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(6, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal', input_shape=(32, 32, 3)))  # 32x32x3 -> 28x28x6\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 28x28x6 -> 14x14x6\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal'))  # 14x14x6 -> 10x10x16\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 10x10x16 -> 5x5x16\n",
    "\n",
    "model.add(Flatten())  # 5x5x16 -> 400\n",
    "model.add(Dense(240, activation='relu',\n",
    "                kernel_initializer='he_normal'))  # 400 ->240\n",
    "model.add(Dense(120, activation='relu', kernel_initializer='he_normal'))  # 240 ->120\n",
    "model.add(Dense(100, activation='softmax'))  # 120 ->100\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # 3.2.1 Global Contrast Normalization (GCN)\n",
    "    samplewise_center=True,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=True,\n",
    "    zca_whitening=True,  # 3.2.2 Zero-phase Component Analysis (ZCA) Whitening\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.2,  # 3.1.1 左右にずらす\n",
    "    height_shift_range=0.2,  # 3.1.2 上下にずらす\n",
    "    brightness_range=None,\n",
    "    shear_range=0.0,\n",
    "    zoom_range=0.0,\n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode=\"nearest\",\n",
    "    cval=0.0,\n",
    "    horizontal_flip=True,  # 3.1.3 左右反転\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0.0,\n",
    "    dtype=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "400/400 [==============================] - 24s 59ms/step - loss: 4.2324 - accuracy: 0.0579 - val_loss: 4.8557 - val_accuracy: 0.0190\n",
      "Epoch 2/30\n",
      "400/400 [==============================] - 23s 59ms/step - loss: 3.8423 - accuracy: 0.1135 - val_loss: 5.2793 - val_accuracy: 0.0173\n",
      "Epoch 3/30\n",
      "400/400 [==============================] - 36s 90ms/step - loss: 3.6592 - accuracy: 0.1415 - val_loss: 5.3419 - val_accuracy: 0.0124\n",
      "Epoch 4/30\n",
      "400/400 [==============================] - 43s 107ms/step - loss: 3.5372 - accuracy: 0.1637 - val_loss: 5.5806 - val_accuracy: 0.0174\n",
      "Epoch 5/30\n",
      "400/400 [==============================] - 46s 115ms/step - loss: 3.4398 - accuracy: 0.1785 - val_loss: 5.9461 - val_accuracy: 0.0172\n",
      "Epoch 6/30\n",
      "400/400 [==============================] - 43s 107ms/step - loss: 3.3721 - accuracy: 0.1904 - val_loss: 5.8216 - val_accuracy: 0.0197\n",
      "Epoch 7/30\n",
      "400/400 [==============================] - 41s 102ms/step - loss: 3.3217 - accuracy: 0.1988 - val_loss: 6.0285 - val_accuracy: 0.0141\n",
      "Epoch 8/30\n",
      "400/400 [==============================] - 38s 96ms/step - loss: 3.2598 - accuracy: 0.2119 - val_loss: 5.8404 - val_accuracy: 0.0239\n",
      "Epoch 9/30\n",
      "400/400 [==============================] - 40s 101ms/step - loss: 3.2145 - accuracy: 0.2187 - val_loss: 6.3888 - val_accuracy: 0.0213\n",
      "Epoch 10/30\n",
      "400/400 [==============================] - 47s 118ms/step - loss: 3.1775 - accuracy: 0.2258 - val_loss: 6.0346 - val_accuracy: 0.0185\n",
      "Epoch 11/30\n",
      "400/400 [==============================] - 49s 122ms/step - loss: 3.1461 - accuracy: 0.2270 - val_loss: 6.7493 - val_accuracy: 0.0161\n",
      "Epoch 12/30\n",
      "400/400 [==============================] - 48s 119ms/step - loss: 3.1200 - accuracy: 0.2350 - val_loss: 6.9703 - val_accuracy: 0.0138\n",
      "Epoch 13/30\n",
      "400/400 [==============================] - 48s 120ms/step - loss: 3.0811 - accuracy: 0.2413 - val_loss: 6.5780 - val_accuracy: 0.0152\n",
      "Epoch 14/30\n",
      "400/400 [==============================] - 48s 119ms/step - loss: 3.0710 - accuracy: 0.2433 - val_loss: 7.1405 - val_accuracy: 0.0151\n",
      "Epoch 15/30\n",
      "400/400 [==============================] - 48s 119ms/step - loss: 3.0373 - accuracy: 0.2523 - val_loss: 6.9962 - val_accuracy: 0.0196\n",
      "Epoch 16/30\n",
      "400/400 [==============================] - 47s 118ms/step - loss: 3.0206 - accuracy: 0.2517 - val_loss: 6.6546 - val_accuracy: 0.0223\n",
      "Epoch 17/30\n",
      "400/400 [==============================] - 47s 118ms/step - loss: 2.9968 - accuracy: 0.2558 - val_loss: 6.4279 - val_accuracy: 0.0175\n",
      "Epoch 18/30\n",
      "400/400 [==============================] - 47s 117ms/step - loss: 2.9638 - accuracy: 0.2638 - val_loss: 6.4756 - val_accuracy: 0.0230\n",
      "Epoch 19/30\n",
      "400/400 [==============================] - 48s 120ms/step - loss: 2.9523 - accuracy: 0.2652 - val_loss: 6.7052 - val_accuracy: 0.0211\n",
      "Epoch 20/30\n",
      "400/400 [==============================] - 48s 120ms/step - loss: 2.9230 - accuracy: 0.2709 - val_loss: 6.7151 - val_accuracy: 0.0221\n",
      "Epoch 21/30\n",
      "400/400 [==============================] - 48s 119ms/step - loss: 2.9198 - accuracy: 0.2700 - val_loss: 6.6884 - val_accuracy: 0.0222\n",
      "Epoch 22/30\n",
      "400/400 [==============================] - 48s 121ms/step - loss: 2.9069 - accuracy: 0.2745 - val_loss: 6.7561 - val_accuracy: 0.0281\n",
      "Epoch 23/30\n",
      "400/400 [==============================] - 48s 120ms/step - loss: 2.8844 - accuracy: 0.2776 - val_loss: 7.0947 - val_accuracy: 0.0232\n",
      "Epoch 24/30\n",
      "400/400 [==============================] - 50s 124ms/step - loss: 2.8760 - accuracy: 0.2794 - val_loss: 7.1790 - val_accuracy: 0.0191\n",
      "Epoch 25/30\n",
      "400/400 [==============================] - 47s 119ms/step - loss: 2.8621 - accuracy: 0.2840 - val_loss: 6.7841 - val_accuracy: 0.0293\n",
      "Epoch 26/30\n",
      "400/400 [==============================] - 47s 118ms/step - loss: 2.8354 - accuracy: 0.2877 - val_loss: 6.9737 - val_accuracy: 0.0241\n",
      "Epoch 27/30\n",
      "400/400 [==============================] - 48s 120ms/step - loss: 2.8280 - accuracy: 0.2903 - val_loss: 6.9272 - val_accuracy: 0.0260\n",
      "Epoch 28/30\n",
      "400/400 [==============================] - 48s 121ms/step - loss: 2.8191 - accuracy: 0.2907 - val_loss: 6.5290 - val_accuracy: 0.0277\n",
      "Epoch 29/30\n",
      "400/400 [==============================] - 49s 123ms/step - loss: 2.8093 - accuracy: 0.2930 - val_loss: 6.9074 - val_accuracy: 0.0246\n",
      "Epoch 30/30\n",
      "400/400 [==============================] - 48s 120ms/step - loss: 2.7967 - accuracy: 0.2952 - val_loss: 7.3064 - val_accuracy: 0.0218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x148131b10>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=100),\n",
    "                    steps_per_epoch=x_train.shape[0] // 100, epochs=30,\n",
    "                    validation_data=(x_valid, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
