{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, Activation, add, Add, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "\n",
    "x_train = x_train.astype('float32')/255.0\n",
    "y_train = np.eye(100)[y_train.astype('int32').flatten()]\n",
    "x_test = x_test.astype('float32')/255.0\n",
    "y_test = np.eye(100)[y_test.astype('int32').flatten()]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train, y_train, test_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(6, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal', input_shape=(32, 32, 3)))  # 32x32x3 -> 28x28x6\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 28x28x6 -> 14x14x6\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal'))  # 14x14x6 -> 10x10x16\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 10x10x16 -> 5x5x16\n",
    "\n",
    "model.add(Flatten())  # 5x5x16 -> 400\n",
    "model.add(Dense(240, activation='relu',\n",
    "                kernel_initializer='he_normal'))  # 400 ->240\n",
    "model.add(Dense(120, activation='relu', kernel_initializer='he_normal'))  # 240 ->120\n",
    "model.add(Dense(100, activation='softmax'))  # 120 ->100\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.0,  # 3.1.1 左右にずらす\n",
    "    height_shift_range=0.0,  # 3.1.2 上下にずらす\n",
    "    horizontal_flip=False,  # 3.1.3 左右反転\n",
    "    # 3.2.1 Global Contrast Normalization (GCN) \n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    zca_whitening=True)  # 3.2.2 Zero-phase Component Analysis (ZCA) Whitening (Falseに設定しているのでここでは使用していない)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "400/400 [==============================] - 11s 27ms/step - loss: 4.0380 - accuracy: 0.0972 - val_loss: 4.4955 - val_accuracy: 0.0364\n",
      "Epoch 2/30\n",
      "400/400 [==============================] - 11s 29ms/step - loss: 3.4243 - accuracy: 0.1940 - val_loss: 4.5530 - val_accuracy: 0.0396\n",
      "Epoch 3/30\n",
      "400/400 [==============================] - 12s 29ms/step - loss: 3.1435 - accuracy: 0.2401 - val_loss: 4.5367 - val_accuracy: 0.0399\n",
      "Epoch 4/30\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 2.9439 - accuracy: 0.2788 - val_loss: 4.9240 - val_accuracy: 0.0196\n",
      "Epoch 5/30\n",
      "400/400 [==============================] - 12s 29ms/step - loss: 2.7815 - accuracy: 0.3103 - val_loss: 4.8448 - val_accuracy: 0.0314\n",
      "Epoch 6/30\n",
      "400/400 [==============================] - 12s 29ms/step - loss: 2.6368 - accuracy: 0.3371 - val_loss: 4.9634 - val_accuracy: 0.0331\n",
      "Epoch 7/30\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 2.5117 - accuracy: 0.3623 - val_loss: 4.8506 - val_accuracy: 0.0260\n",
      "Epoch 8/30\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 2.3919 - accuracy: 0.3864 - val_loss: 5.1537 - val_accuracy: 0.0193\n",
      "Epoch 9/30\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 2.2717 - accuracy: 0.4150 - val_loss: 5.2964 - val_accuracy: 0.0166\n",
      "Epoch 10/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 2.1634 - accuracy: 0.4318 - val_loss: 5.3655 - val_accuracy: 0.0195\n",
      "Epoch 11/30\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 2.0574 - accuracy: 0.4572 - val_loss: 5.4483 - val_accuracy: 0.0193\n",
      "Epoch 12/30\n",
      "400/400 [==============================] - 12s 29ms/step - loss: 1.9610 - accuracy: 0.4780 - val_loss: 5.6855 - val_accuracy: 0.0172\n",
      "Epoch 13/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.8633 - accuracy: 0.4984 - val_loss: 5.7862 - val_accuracy: 0.0178\n",
      "Epoch 14/30\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 1.7710 - accuracy: 0.5170 - val_loss: 5.9039 - val_accuracy: 0.0173\n",
      "Epoch 15/30\n",
      "400/400 [==============================] - 12s 29ms/step - loss: 1.6938 - accuracy: 0.5380 - val_loss: 5.9555 - val_accuracy: 0.0198\n",
      "Epoch 16/30\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 1.6101 - accuracy: 0.5581 - val_loss: 6.0251 - val_accuracy: 0.0182\n",
      "Epoch 17/30\n",
      "400/400 [==============================] - 12s 29ms/step - loss: 1.5398 - accuracy: 0.5712 - val_loss: 5.9485 - val_accuracy: 0.0181\n",
      "Epoch 18/30\n",
      "400/400 [==============================] - 12s 29ms/step - loss: 1.4612 - accuracy: 0.5929 - val_loss: 6.2926 - val_accuracy: 0.0216\n",
      "Epoch 19/30\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 1.3920 - accuracy: 0.6090 - val_loss: 6.5221 - val_accuracy: 0.0233\n",
      "Epoch 20/30\n",
      "400/400 [==============================] - 12s 29ms/step - loss: 1.3329 - accuracy: 0.6216 - val_loss: 6.3015 - val_accuracy: 0.0203\n",
      "Epoch 21/30\n",
      "400/400 [==============================] - 12s 29ms/step - loss: 1.2654 - accuracy: 0.6383 - val_loss: 6.8885 - val_accuracy: 0.0181\n",
      "Epoch 22/30\n",
      "400/400 [==============================] - 12s 29ms/step - loss: 1.2005 - accuracy: 0.6517 - val_loss: 7.1604 - val_accuracy: 0.0172\n",
      "Epoch 23/30\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 1.1582 - accuracy: 0.6626 - val_loss: 7.0124 - val_accuracy: 0.0195\n",
      "Epoch 24/30\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 1.0998 - accuracy: 0.6762 - val_loss: 7.2119 - val_accuracy: 0.0171\n",
      "Epoch 25/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 1.0584 - accuracy: 0.6879 - val_loss: 6.9827 - val_accuracy: 0.0203\n",
      "Epoch 26/30\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 1.0003 - accuracy: 0.7013 - val_loss: 7.9165 - val_accuracy: 0.0191\n",
      "Epoch 27/30\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.9543 - accuracy: 0.7151 - val_loss: 8.1993 - val_accuracy: 0.0173\n",
      "Epoch 28/30\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 0.9099 - accuracy: 0.7245 - val_loss: 7.6878 - val_accuracy: 0.0184\n",
      "Epoch 29/30\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 0.8787 - accuracy: 0.7365 - val_loss: 8.1503 - val_accuracy: 0.0205\n",
      "Epoch 30/30\n",
      "400/400 [==============================] - 17s 43ms/step - loss: 0.8368 - accuracy: 0.7456 - val_loss: 8.0158 - val_accuracy: 0.0197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14b168310>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=100),\n",
    "                    steps_per_epoch=x_train.shape[0] // 100, epochs=30,\n",
    "                    validation_data=(x_valid, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
