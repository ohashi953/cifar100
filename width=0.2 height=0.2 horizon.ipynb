{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, Activation, add, Add, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "\n",
    "x_train = x_train.astype('float32')/255.0\n",
    "y_train = np.eye(100)[y_train.astype('int32').flatten()]\n",
    "x_test = x_test.astype('float32')/255.0\n",
    "y_test = np.eye(100)[y_test.astype('int32').flatten()]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train, y_train, test_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(6, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal', input_shape=(32, 32, 3)))  # 32x32x3 -> 28x28x6\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 28x28x6 -> 14x14x6\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal'))  # 14x14x6 -> 10x10x16\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 10x10x16 -> 5x5x16\n",
    "\n",
    "model.add(Flatten())  # 5x5x16 -> 400\n",
    "model.add(Dense(240, activation='relu',\n",
    "                kernel_initializer='he_normal'))  # 400 ->240\n",
    "model.add(Dense(120, activation='relu', kernel_initializer='he_normal'))  # 240 ->120\n",
    "model.add(Dense(100, activation='softmax'))  # 120 ->100\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # 3.2.1 Global Contrast Normalization (GCN)\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,  # 3.2.2 Zero-phase Component Analysis (ZCA) Whitening\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.2,  # 3.1.1 左右にずらす\n",
    "    height_shift_range=0.2,  # 3.1.2 上下にずらす\n",
    "    brightness_range=None,\n",
    "    shear_range=0.0,\n",
    "    zoom_range=0.0,\n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode=\"nearest\",\n",
    "    cval=0.0,\n",
    "    horizontal_flip=True,  # 3.1.3 左右反転\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0.0,\n",
    "    dtype=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "400/400 [==============================] - 18s 46ms/step - loss: 4.2548 - accuracy: 0.0503 - val_loss: 3.9232 - val_accuracy: 0.0945\n",
      "Epoch 2/30\n",
      "400/400 [==============================] - 19s 46ms/step - loss: 3.8555 - accuracy: 0.1049 - val_loss: 3.5910 - val_accuracy: 0.1491\n",
      "Epoch 3/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 3.6482 - accuracy: 0.1390 - val_loss: 3.4301 - val_accuracy: 0.1758\n",
      "Epoch 4/30\n",
      "400/400 [==============================] - 18s 46ms/step - loss: 3.5066 - accuracy: 0.1599 - val_loss: 3.3724 - val_accuracy: 0.1822\n",
      "Epoch 5/30\n",
      "400/400 [==============================] - 19s 46ms/step - loss: 3.4146 - accuracy: 0.1797 - val_loss: 3.2554 - val_accuracy: 0.2079\n",
      "Epoch 6/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 3.3489 - accuracy: 0.1909 - val_loss: 3.2051 - val_accuracy: 0.2216\n",
      "Epoch 7/30\n",
      "400/400 [==============================] - 19s 48ms/step - loss: 3.2823 - accuracy: 0.2031 - val_loss: 3.1615 - val_accuracy: 0.2259\n",
      "Epoch 8/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 3.2340 - accuracy: 0.2068 - val_loss: 3.0930 - val_accuracy: 0.2419\n",
      "Epoch 9/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 3.2000 - accuracy: 0.2174 - val_loss: 3.0474 - val_accuracy: 0.2448\n",
      "Epoch 10/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 3.1482 - accuracy: 0.2284 - val_loss: 3.0230 - val_accuracy: 0.2491\n",
      "Epoch 11/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 3.1239 - accuracy: 0.2335 - val_loss: 3.0096 - val_accuracy: 0.2533\n",
      "Epoch 12/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 3.0887 - accuracy: 0.2384 - val_loss: 2.9930 - val_accuracy: 0.2641\n",
      "Epoch 13/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 3.0658 - accuracy: 0.2417 - val_loss: 2.9543 - val_accuracy: 0.2663\n",
      "Epoch 14/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 3.0501 - accuracy: 0.2459 - val_loss: 2.9545 - val_accuracy: 0.2640\n",
      "Epoch 15/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 3.0238 - accuracy: 0.2503 - val_loss: 2.9959 - val_accuracy: 0.2578\n",
      "Epoch 16/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 3.0054 - accuracy: 0.2562 - val_loss: 2.9305 - val_accuracy: 0.2737\n",
      "Epoch 17/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 2.9781 - accuracy: 0.2608 - val_loss: 2.8991 - val_accuracy: 0.2834\n",
      "Epoch 18/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 2.9660 - accuracy: 0.2626 - val_loss: 2.8779 - val_accuracy: 0.2834\n",
      "Epoch 19/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 2.9343 - accuracy: 0.2674 - val_loss: 2.8523 - val_accuracy: 0.2877\n",
      "Epoch 20/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 2.9191 - accuracy: 0.2713 - val_loss: 2.8925 - val_accuracy: 0.2829\n",
      "Epoch 21/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 2.9050 - accuracy: 0.2734 - val_loss: 2.8973 - val_accuracy: 0.2852\n",
      "Epoch 22/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 2.8839 - accuracy: 0.2777 - val_loss: 2.8486 - val_accuracy: 0.2922\n",
      "Epoch 23/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 2.8637 - accuracy: 0.2823 - val_loss: 2.8058 - val_accuracy: 0.3006\n",
      "Epoch 24/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 2.8477 - accuracy: 0.2837 - val_loss: 2.8404 - val_accuracy: 0.2952\n",
      "Epoch 25/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 2.8444 - accuracy: 0.2869 - val_loss: 2.9328 - val_accuracy: 0.2777\n",
      "Epoch 26/30\n",
      "400/400 [==============================] - 19s 48ms/step - loss: 2.8316 - accuracy: 0.2910 - val_loss: 2.7814 - val_accuracy: 0.3043\n",
      "Epoch 27/30\n",
      "400/400 [==============================] - 19s 48ms/step - loss: 2.8195 - accuracy: 0.2904 - val_loss: 2.8585 - val_accuracy: 0.2898\n",
      "Epoch 28/30\n",
      "400/400 [==============================] - 19s 48ms/step - loss: 2.8069 - accuracy: 0.2945 - val_loss: 2.8474 - val_accuracy: 0.2909\n",
      "Epoch 29/30\n",
      "400/400 [==============================] - 19s 48ms/step - loss: 2.8072 - accuracy: 0.2934 - val_loss: 2.8550 - val_accuracy: 0.2908\n",
      "Epoch 30/30\n",
      "400/400 [==============================] - 19s 48ms/step - loss: 2.7882 - accuracy: 0.2983 - val_loss: 2.7426 - val_accuracy: 0.3126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1426a4310>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=100),\n",
    "                    steps_per_epoch=x_train.shape[0] // 100, epochs=30,\n",
    "                    validation_data=(x_valid, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
