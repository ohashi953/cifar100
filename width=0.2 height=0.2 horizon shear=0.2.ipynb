{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, Activation, add, Add, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "\n",
    "x_train = x_train.astype('float32')/255.0\n",
    "y_train = np.eye(100)[y_train.astype('int32').flatten()]\n",
    "x_test = x_test.astype('float32')/255.0\n",
    "y_test = np.eye(100)[y_test.astype('int32').flatten()]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train, y_train, test_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(6, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal', input_shape=(32, 32, 3)))  # 32x32x3 -> 28x28x6\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 28x28x6 -> 14x14x6\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal'))  # 14x14x6 -> 10x10x16\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 10x10x16 -> 5x5x16\n",
    "\n",
    "model.add(Flatten())  # 5x5x16 -> 400\n",
    "model.add(Dense(240, activation='relu',\n",
    "                kernel_initializer='he_normal'))  # 400 ->240\n",
    "model.add(Dense(120, activation='relu', kernel_initializer='he_normal'))  # 240 ->120\n",
    "model.add(Dense(100, activation='softmax'))  # 120 ->100\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.2,  # 3.1.1 左右にずらす\n",
    "    height_shift_range=0.2,  # 3.1.2 上下にずらす\n",
    "    brightness_range=None,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.0,\n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode=\"nearest\",\n",
    "    cval=0.0,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0.0,\n",
    "    dtype=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "400/400 [==============================] - 34s 84ms/step - loss: 4.2062 - accuracy: 0.0573 - val_loss: 3.8926 - val_accuracy: 0.1037\n",
      "Epoch 2/30\n",
      "400/400 [==============================] - 37s 94ms/step - loss: 3.8408 - accuracy: 0.1085 - val_loss: 3.6163 - val_accuracy: 0.1457\n",
      "Epoch 3/30\n",
      "400/400 [==============================] - 41s 103ms/step - loss: 3.6339 - accuracy: 0.1419 - val_loss: 3.4307 - val_accuracy: 0.1768\n",
      "Epoch 4/30\n",
      "400/400 [==============================] - 39s 98ms/step - loss: 3.5028 - accuracy: 0.1655 - val_loss: 3.3818 - val_accuracy: 0.1900\n",
      "Epoch 5/30\n",
      "400/400 [==============================] - 39s 97ms/step - loss: 3.4112 - accuracy: 0.1815 - val_loss: 3.3269 - val_accuracy: 0.1987\n",
      "Epoch 6/30\n",
      "400/400 [==============================] - 39s 97ms/step - loss: 3.3327 - accuracy: 0.1936 - val_loss: 3.2318 - val_accuracy: 0.2177\n",
      "Epoch 7/30\n",
      "400/400 [==============================] - 39s 97ms/step - loss: 3.2708 - accuracy: 0.2053 - val_loss: 3.1786 - val_accuracy: 0.2233\n",
      "Epoch 8/30\n",
      "400/400 [==============================] - 39s 98ms/step - loss: 3.2307 - accuracy: 0.2161 - val_loss: 3.1824 - val_accuracy: 0.2323\n",
      "Epoch 9/30\n",
      "400/400 [==============================] - 39s 97ms/step - loss: 3.1922 - accuracy: 0.2213 - val_loss: 3.0366 - val_accuracy: 0.2583\n",
      "Epoch 10/30\n",
      "400/400 [==============================] - 40s 99ms/step - loss: 3.1494 - accuracy: 0.2258 - val_loss: 3.0594 - val_accuracy: 0.2540\n",
      "Epoch 11/30\n",
      "400/400 [==============================] - 39s 97ms/step - loss: 3.1210 - accuracy: 0.2355 - val_loss: 3.0650 - val_accuracy: 0.2484\n",
      "Epoch 12/30\n",
      "400/400 [==============================] - 39s 97ms/step - loss: 3.0878 - accuracy: 0.2404 - val_loss: 2.9856 - val_accuracy: 0.2649\n",
      "Epoch 13/30\n",
      "400/400 [==============================] - 39s 98ms/step - loss: 3.0653 - accuracy: 0.2445 - val_loss: 3.0234 - val_accuracy: 0.2575\n",
      "Epoch 14/30\n",
      "400/400 [==============================] - 40s 100ms/step - loss: 3.0370 - accuracy: 0.2522 - val_loss: 2.9374 - val_accuracy: 0.2740\n",
      "Epoch 15/30\n",
      "400/400 [==============================] - 39s 98ms/step - loss: 3.0184 - accuracy: 0.2545 - val_loss: 2.9453 - val_accuracy: 0.2683\n",
      "Epoch 16/30\n",
      "400/400 [==============================] - 39s 98ms/step - loss: 2.9931 - accuracy: 0.2580 - val_loss: 2.9150 - val_accuracy: 0.2822\n",
      "Epoch 17/30\n",
      "400/400 [==============================] - 39s 99ms/step - loss: 2.9840 - accuracy: 0.2615 - val_loss: 3.1067 - val_accuracy: 0.2445\n",
      "Epoch 18/30\n",
      "400/400 [==============================] - 39s 97ms/step - loss: 2.9633 - accuracy: 0.2648 - val_loss: 2.8802 - val_accuracy: 0.2826\n",
      "Epoch 19/30\n",
      "400/400 [==============================] - 39s 98ms/step - loss: 2.9462 - accuracy: 0.2677 - val_loss: 2.8683 - val_accuracy: 0.2876\n",
      "Epoch 20/30\n",
      "400/400 [==============================] - 40s 101ms/step - loss: 2.9337 - accuracy: 0.2700 - val_loss: 2.8685 - val_accuracy: 0.2851\n",
      "Epoch 21/30\n",
      "400/400 [==============================] - 39s 98ms/step - loss: 2.9032 - accuracy: 0.2729 - val_loss: 2.8470 - val_accuracy: 0.2960\n",
      "Epoch 22/30\n",
      "400/400 [==============================] - 39s 97ms/step - loss: 2.8982 - accuracy: 0.2764 - val_loss: 2.9364 - val_accuracy: 0.2808\n",
      "Epoch 23/30\n",
      "400/400 [==============================] - 39s 99ms/step - loss: 2.8911 - accuracy: 0.2780 - val_loss: 2.8799 - val_accuracy: 0.2893\n",
      "Epoch 24/30\n",
      "400/400 [==============================] - 39s 96ms/step - loss: 2.8714 - accuracy: 0.2808 - val_loss: 2.7973 - val_accuracy: 0.2994\n",
      "Epoch 25/30\n",
      "400/400 [==============================] - 39s 98ms/step - loss: 2.8543 - accuracy: 0.2845 - val_loss: 2.8609 - val_accuracy: 0.2917\n",
      "Epoch 26/30\n",
      "400/400 [==============================] - 40s 99ms/step - loss: 2.8422 - accuracy: 0.2873 - val_loss: 2.8985 - val_accuracy: 0.2877\n",
      "Epoch 27/30\n",
      "400/400 [==============================] - 37s 93ms/step - loss: 2.8339 - accuracy: 0.2897 - val_loss: 2.8440 - val_accuracy: 0.2939\n",
      "Epoch 28/30\n",
      "400/400 [==============================] - 31s 76ms/step - loss: 2.8262 - accuracy: 0.2905 - val_loss: 2.7998 - val_accuracy: 0.3022\n",
      "Epoch 29/30\n",
      "400/400 [==============================] - 31s 76ms/step - loss: 2.8097 - accuracy: 0.2965 - val_loss: 2.8360 - val_accuracy: 0.2909\n",
      "Epoch 30/30\n",
      "400/400 [==============================] - 32s 81ms/step - loss: 2.7994 - accuracy: 0.2999 - val_loss: 2.8642 - val_accuracy: 0.2923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14b04c310>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=100),\n",
    "                    steps_per_epoch=x_train.shape[0] // 100, epochs=30,\n",
    "                    validation_data=(x_valid, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
