{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, Activation, add, Add, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "\n",
    "x_train = x_train.astype('float32')/255.0\n",
    "y_train = np.eye(100)[y_train.astype('int32').flatten()]\n",
    "x_test = x_test.astype('float32')/255.0\n",
    "y_test = np.eye(100)[y_test.astype('int32').flatten()]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train, y_train, test_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(6, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal', input_shape=(32, 32, 3)))  # 32x32x3 -> 28x28x6\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 28x28x6 -> 14x14x6\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal'))  # 14x14x6 -> 10x10x16\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 10x10x16 -> 5x5x16\n",
    "\n",
    "model.add(Flatten())  # 5x5x16 -> 400\n",
    "model.add(Dense(240, activation='relu',\n",
    "                kernel_initializer='he_normal'))  # 400 ->240\n",
    "model.add(Dense(120, activation='relu', kernel_initializer='he_normal'))  # 240 ->120\n",
    "model.add(Dense(100, activation='softmax'))  # 120 ->100\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.2,  # 3.1.1 左右にずらす\n",
    "    height_shift_range=0.2,  # 3.1.2 上下にずらす\n",
    "    brightness_range=None,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode=\"nearest\",\n",
    "    cval=0.0,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0.0,\n",
    "    dtype=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "400/400 [==============================] - 36s 91ms/step - loss: 4.1726 - accuracy: 0.0604 - val_loss: 3.7419 - val_accuracy: 0.1357\n",
      "Epoch 2/30\n",
      "400/400 [==============================] - 43s 107ms/step - loss: 3.7604 - accuracy: 0.1235 - val_loss: 3.5303 - val_accuracy: 0.1587\n",
      "Epoch 3/30\n",
      "400/400 [==============================] - 40s 101ms/step - loss: 3.6021 - accuracy: 0.1489 - val_loss: 3.3765 - val_accuracy: 0.1867\n",
      "Epoch 4/30\n",
      "400/400 [==============================] - 40s 100ms/step - loss: 3.4949 - accuracy: 0.1687 - val_loss: 3.2854 - val_accuracy: 0.2120\n",
      "Epoch 5/30\n",
      "400/400 [==============================] - 40s 99ms/step - loss: 3.4080 - accuracy: 0.1828 - val_loss: 3.2522 - val_accuracy: 0.2148\n",
      "Epoch 6/30\n",
      "400/400 [==============================] - 40s 99ms/step - loss: 3.3411 - accuracy: 0.1917 - val_loss: 3.1878 - val_accuracy: 0.2275\n",
      "Epoch 7/30\n",
      "400/400 [==============================] - 40s 100ms/step - loss: 3.2950 - accuracy: 0.2006 - val_loss: 3.1054 - val_accuracy: 0.2356\n",
      "Epoch 8/30\n",
      "400/400 [==============================] - 40s 100ms/step - loss: 3.2434 - accuracy: 0.2104 - val_loss: 3.0150 - val_accuracy: 0.2639\n",
      "Epoch 9/30\n",
      "400/400 [==============================] - 40s 100ms/step - loss: 3.2094 - accuracy: 0.2188 - val_loss: 3.0975 - val_accuracy: 0.2345\n",
      "Epoch 10/30\n",
      "400/400 [==============================] - 40s 100ms/step - loss: 3.1794 - accuracy: 0.2220 - val_loss: 3.0763 - val_accuracy: 0.2488\n",
      "Epoch 11/30\n",
      "400/400 [==============================] - 40s 100ms/step - loss: 3.1444 - accuracy: 0.2296 - val_loss: 2.9797 - val_accuracy: 0.2687\n",
      "Epoch 12/30\n",
      "400/400 [==============================] - 41s 102ms/step - loss: 3.1259 - accuracy: 0.2329 - val_loss: 3.0810 - val_accuracy: 0.2483\n",
      "Epoch 13/30\n",
      "400/400 [==============================] - 41s 102ms/step - loss: 3.0921 - accuracy: 0.2396 - val_loss: 3.0381 - val_accuracy: 0.2549\n",
      "Epoch 14/30\n",
      "400/400 [==============================] - 40s 101ms/step - loss: 3.0607 - accuracy: 0.2460 - val_loss: 2.9858 - val_accuracy: 0.2667\n",
      "Epoch 15/30\n",
      "400/400 [==============================] - 41s 102ms/step - loss: 3.0430 - accuracy: 0.2484 - val_loss: 2.9292 - val_accuracy: 0.2819\n",
      "Epoch 16/30\n",
      "400/400 [==============================] - 41s 102ms/step - loss: 3.0348 - accuracy: 0.2479 - val_loss: 2.9853 - val_accuracy: 0.2675\n",
      "Epoch 17/30\n",
      "400/400 [==============================] - 41s 102ms/step - loss: 3.0145 - accuracy: 0.2548 - val_loss: 2.9378 - val_accuracy: 0.2790\n",
      "Epoch 18/30\n",
      "400/400 [==============================] - 41s 103ms/step - loss: 2.9922 - accuracy: 0.2578 - val_loss: 2.8930 - val_accuracy: 0.2903\n",
      "Epoch 19/30\n",
      "400/400 [==============================] - 42s 104ms/step - loss: 2.9732 - accuracy: 0.2609 - val_loss: 2.8609 - val_accuracy: 0.2893\n",
      "Epoch 20/30\n",
      "400/400 [==============================] - 40s 101ms/step - loss: 2.9644 - accuracy: 0.2619 - val_loss: 2.8511 - val_accuracy: 0.2880\n",
      "Epoch 21/30\n",
      "400/400 [==============================] - 41s 102ms/step - loss: 2.9486 - accuracy: 0.2678 - val_loss: 2.8222 - val_accuracy: 0.2977\n",
      "Epoch 22/30\n",
      "400/400 [==============================] - 40s 101ms/step - loss: 2.9349 - accuracy: 0.2695 - val_loss: 2.8481 - val_accuracy: 0.2989\n",
      "Epoch 23/30\n",
      "400/400 [==============================] - 41s 102ms/step - loss: 2.9265 - accuracy: 0.2707 - val_loss: 2.9581 - val_accuracy: 0.2766\n",
      "Epoch 24/30\n",
      "400/400 [==============================] - 40s 101ms/step - loss: 2.9155 - accuracy: 0.2725 - val_loss: 2.8126 - val_accuracy: 0.3036\n",
      "Epoch 25/30\n",
      "400/400 [==============================] - 41s 102ms/step - loss: 2.9034 - accuracy: 0.2740 - val_loss: 2.7985 - val_accuracy: 0.3025\n",
      "Epoch 26/30\n",
      "400/400 [==============================] - 34s 86ms/step - loss: 2.8788 - accuracy: 0.2765 - val_loss: 2.9577 - val_accuracy: 0.2776\n",
      "Epoch 27/30\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 2.8709 - accuracy: 0.2839 - val_loss: 2.8568 - val_accuracy: 0.2944\n",
      "Epoch 28/30\n",
      "400/400 [==============================] - 32s 81ms/step - loss: 2.8648 - accuracy: 0.2831 - val_loss: 2.7951 - val_accuracy: 0.3052\n",
      "Epoch 29/30\n",
      "400/400 [==============================] - 29s 73ms/step - loss: 2.8589 - accuracy: 0.2850 - val_loss: 2.7901 - val_accuracy: 0.3076\n",
      "Epoch 30/30\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 2.8501 - accuracy: 0.2855 - val_loss: 2.7578 - val_accuracy: 0.3126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13fad0b10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=100),\n",
    "                    steps_per_epoch=x_train.shape[0] // 100, epochs=30,\n",
    "                    validation_data=(x_valid, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
