{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, Activation, add, Add, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "\n",
    "x_train = x_train.astype('float32')/255.0\n",
    "y_train = np.eye(100)[y_train.astype('int32').flatten()]\n",
    "x_test = x_test.astype('float32')/255.0\n",
    "y_test = np.eye(100)[y_test.astype('int32').flatten()]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train, y_train, test_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(6, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal', input_shape=(32, 32, 3)))  # 32x32x3 -> 28x28x6\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 28x28x6 -> 14x14x6\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal'))  # 14x14x6 -> 10x10x16\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 10x10x16 -> 5x5x16\n",
    "\n",
    "model.add(Flatten())  # 5x5x16 -> 400\n",
    "model.add(Dense(240, activation='relu',\n",
    "                kernel_initializer='he_normal'))  # 400 ->240\n",
    "model.add(Dense(120, activation='relu', kernel_initializer='he_normal'))  # 240 ->120\n",
    "model.add(Dense(100, activation='softmax'))  # 120 ->100\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # 3.2.1 Global Contrast Normalization (GCN)\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,  # 3.2.2 Zero-phase Component Analysis (ZCA) Whitening\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.1,  # 3.1.1 左右にずらす\n",
    "    height_shift_range=0.0,  # 3.1.2 上下にずらす\n",
    "    brightness_range=None,\n",
    "    shear_range=0.0,\n",
    "    zoom_range=0.0,\n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode=\"nearest\",\n",
    "    cval=0.0,\n",
    "    horizontal_flip=True,  # 3.1.3 左右反転\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0.0,\n",
    "    dtype=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 4.0155 - accuracy: 0.0925 - val_loss: 3.6769 - val_accuracy: 0.1432\n",
      "Epoch 2/30\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 3.4973 - accuracy: 0.1717 - val_loss: 3.3977 - val_accuracy: 0.1899\n",
      "Epoch 3/30\n",
      "400/400 [==============================] - 18s 46ms/step - loss: 3.2564 - accuracy: 0.2125 - val_loss: 3.1899 - val_accuracy: 0.2253\n",
      "Epoch 4/30\n",
      "400/400 [==============================] - 18s 46ms/step - loss: 3.1112 - accuracy: 0.2400 - val_loss: 3.2157 - val_accuracy: 0.2276\n",
      "Epoch 5/30\n",
      "400/400 [==============================] - 18s 46ms/step - loss: 2.9813 - accuracy: 0.2633 - val_loss: 3.0309 - val_accuracy: 0.2643\n",
      "Epoch 6/30\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 2.9174 - accuracy: 0.2735 - val_loss: 3.0522 - val_accuracy: 0.2555\n",
      "Epoch 7/30\n",
      "400/400 [==============================] - 18s 44ms/step - loss: 2.8490 - accuracy: 0.2922 - val_loss: 2.9367 - val_accuracy: 0.2832\n",
      "Epoch 8/30\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 2.7929 - accuracy: 0.3012 - val_loss: 2.9354 - val_accuracy: 0.2824\n",
      "Epoch 9/30\n",
      "400/400 [==============================] - 18s 44ms/step - loss: 2.7371 - accuracy: 0.3099 - val_loss: 2.9108 - val_accuracy: 0.2832\n",
      "Epoch 10/30\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 2.6953 - accuracy: 0.3176 - val_loss: 2.8819 - val_accuracy: 0.2933\n",
      "Epoch 11/30\n",
      "400/400 [==============================] - 18s 46ms/step - loss: 2.6494 - accuracy: 0.3284 - val_loss: 2.8404 - val_accuracy: 0.3034\n",
      "Epoch 12/30\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 2.6046 - accuracy: 0.3358 - val_loss: 2.8487 - val_accuracy: 0.3017\n",
      "Epoch 13/30\n",
      "400/400 [==============================] - 19s 46ms/step - loss: 2.5647 - accuracy: 0.3464 - val_loss: 2.8334 - val_accuracy: 0.3077\n",
      "Epoch 14/30\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 2.5297 - accuracy: 0.3531 - val_loss: 2.8067 - val_accuracy: 0.3117\n",
      "Epoch 15/30\n",
      "400/400 [==============================] - 18s 46ms/step - loss: 2.5104 - accuracy: 0.3581 - val_loss: 2.8288 - val_accuracy: 0.3054\n",
      "Epoch 16/30\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 2.4838 - accuracy: 0.3620 - val_loss: 2.7902 - val_accuracy: 0.3191\n",
      "Epoch 17/30\n",
      "400/400 [==============================] - 19s 46ms/step - loss: 2.4449 - accuracy: 0.3707 - val_loss: 2.8220 - val_accuracy: 0.3100\n",
      "Epoch 18/30\n",
      "400/400 [==============================] - 19s 46ms/step - loss: 2.4227 - accuracy: 0.3724 - val_loss: 2.7695 - val_accuracy: 0.3253\n",
      "Epoch 19/30\n",
      "400/400 [==============================] - 18s 46ms/step - loss: 2.3853 - accuracy: 0.3819 - val_loss: 2.8004 - val_accuracy: 0.3188\n",
      "Epoch 20/30\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 2.3770 - accuracy: 0.3831 - val_loss: 2.8031 - val_accuracy: 0.3168\n",
      "Epoch 21/30\n",
      "400/400 [==============================] - 18s 44ms/step - loss: 2.3543 - accuracy: 0.3896 - val_loss: 2.7619 - val_accuracy: 0.3277\n",
      "Epoch 22/30\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 2.3322 - accuracy: 0.3932 - val_loss: 2.8136 - val_accuracy: 0.3135\n",
      "Epoch 23/30\n",
      "400/400 [==============================] - 18s 44ms/step - loss: 2.3065 - accuracy: 0.3949 - val_loss: 2.7896 - val_accuracy: 0.3270\n",
      "Epoch 24/30\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 2.2940 - accuracy: 0.4013 - val_loss: 2.8048 - val_accuracy: 0.3191\n",
      "Epoch 25/30\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 2.2649 - accuracy: 0.4072 - val_loss: 2.7749 - val_accuracy: 0.3250\n",
      "Epoch 26/30\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 2.2391 - accuracy: 0.4123 - val_loss: 2.7729 - val_accuracy: 0.3323\n",
      "Epoch 27/30\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 2.2197 - accuracy: 0.4135 - val_loss: 2.7832 - val_accuracy: 0.3316\n",
      "Epoch 28/30\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 2.2072 - accuracy: 0.4152 - val_loss: 2.7898 - val_accuracy: 0.3274\n",
      "Epoch 29/30\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 2.1948 - accuracy: 0.4222 - val_loss: 2.8068 - val_accuracy: 0.3313\n",
      "Epoch 30/30\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 2.1803 - accuracy: 0.4246 - val_loss: 2.8493 - val_accuracy: 0.3262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x144be8ad0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=100),\n",
    "                    steps_per_epoch=x_train.shape[0] // 100, epochs=30,\n",
    "                    validation_data=(x_valid, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
